{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Author: Jimena Baripatti\n",
    "\n",
    "Dataset: MiniBooNE particle identification Data Set\n",
    "\n",
    "*source: https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification *\n",
    "\n",
    "\n",
    "SUMMARY: The purpose of this project is to compare two clasiffier models and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "\n",
    "INTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "The submitted file is set up as follows. In the first line is the the number of signal events followed by the number of background events. The signal events come first, followed by the background events. Each line, after the first line has the 50 particle ID variables for one event.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "50 particle ID variables (real) for each event.\n",
    "\n",
    "\n",
    "For more information see: data/external/Boosted Decision Trees as an Alternative to ANN for Particle Identification.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "from src.data import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 36499 93565\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"/Users/jbaripatti/machine_learning_proj/data/raw/MiniBooNE_PID.txt\").readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jbaripatti/machine_learning_proj/data/raw/\"\n",
    "filename = \"MiniBooNE_PID.txt\"\n",
    "file_path = path + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open txt file in reading mode\n",
    "with open(file_path, 'r') as f:\n",
    "    first_line = f.readline().strip()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the first line is the the number of signal events followed by \n",
    "#the number of background events. \n",
    "\n",
    "num_sig = int(first_line.split(\" \")[0])\n",
    "num_bg = int(first_line.split(\" \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36499 93565\n"
     ]
    }
   ],
   "source": [
    "print(num_sig, num_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The signal events come first, followed by the background events.\n",
    "# Binary clasiffier. y is the label, 1 is signal event and 0 is background event.\n",
    "y = np.append(np.ones(num_sig), np.zeros(num_bg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each line, after the first line has the 50 particle ID variables for one event.\n",
    "X = np.loadtxt(file_path, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130064, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape y to add it as an attribute of each vector\n",
    "y.shape[0], 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add y\n",
    "data = np.append(X, np.reshape(y, [y.shape[0], 1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data\n",
    "data_name = 'data_preprocessed'\n",
    "data_path = \"/Users/jbaripatti/machine_learning_proj/data/interim/\" + data_name\n",
    "np.savetxt(data_path, data, delimiter= \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
