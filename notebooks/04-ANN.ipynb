{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "#always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "from src.data import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jbaripatti/machine_learning_proj/data/interim/\"\n",
    "name = 'data_interim.txt'\n",
    "filepath = path + name\n",
    "data = np.loadtxt(filepath, delimiter=\",\")\n",
    "X_train, y_train, X_test, y_test = make_dataset.split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training set, then will use the same transformation to the test set.\n",
    "from sklearn.preprocessing import Normalizer\n",
    "X_train = Normalizer().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 50 input features and one target variable. \n",
    "### 2 Hidden layers. Each hidden layer will have 25 nodes.\n",
    "\n",
    "ReLu will be the activation function for hidden layers. As this is a binary classification problem we will use sigmoid as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(25, activation='relu', kernel_initializer='random_normal', input_dim=50))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(25, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/finalprojectML/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "104051/104051 [==============================] - 10s 100us/step - loss: 0.3414 - acc: 0.8521\n",
      "Epoch 2/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.2992 - acc: 0.8735\n",
      "Epoch 3/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2772 - acc: 0.8840\n",
      "Epoch 4/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.2585 - acc: 0.8924\n",
      "Epoch 5/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.2465 - acc: 0.8982\n",
      "Epoch 6/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.2380 - acc: 0.9025\n",
      "Epoch 7/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2326 - acc: 0.9041\n",
      "Epoch 8/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.2279 - acc: 0.9067\n",
      "Epoch 9/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2260 - acc: 0.9070\n",
      "Epoch 10/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.2230 - acc: 0.9088\n",
      "Epoch 11/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.2216 - acc: 0.9095\n",
      "Epoch 12/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.2194 - acc: 0.9099\n",
      "Epoch 13/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2164 - acc: 0.9105\n",
      "Epoch 14/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2127 - acc: 0.9126\n",
      "Epoch 15/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2078 - acc: 0.9146\n",
      "Epoch 16/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2040 - acc: 0.9159\n",
      "Epoch 17/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.2013 - acc: 0.9171\n",
      "Epoch 18/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1995 - acc: 0.9185\n",
      "Epoch 19/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1972 - acc: 0.9195\n",
      "Epoch 20/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1963 - acc: 0.9191\n",
      "Epoch 21/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1948 - acc: 0.9201\n",
      "Epoch 22/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1943 - acc: 0.9203\n",
      "Epoch 23/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1929 - acc: 0.9209\n",
      "Epoch 24/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1914 - acc: 0.9219\n",
      "Epoch 25/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1895 - acc: 0.9221\n",
      "Epoch 26/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1882 - acc: 0.9226\n",
      "Epoch 27/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1875 - acc: 0.9229\n",
      "Epoch 28/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1866 - acc: 0.9244\n",
      "Epoch 29/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1854 - acc: 0.9237\n",
      "Epoch 30/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1857 - acc: 0.9236\n",
      "Epoch 31/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1847 - acc: 0.9247\n",
      "Epoch 32/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1838 - acc: 0.9253\n",
      "Epoch 33/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1824 - acc: 0.9252\n",
      "Epoch 34/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1823 - acc: 0.9247\n",
      "Epoch 35/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1815 - acc: 0.9256\n",
      "Epoch 36/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1813 - acc: 0.9265\n",
      "Epoch 37/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1802 - acc: 0.9266\n",
      "Epoch 38/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1801 - acc: 0.9267\n",
      "Epoch 39/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1801 - acc: 0.9269\n",
      "Epoch 40/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1796 - acc: 0.9270\n",
      "Epoch 41/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1801 - acc: 0.9262\n",
      "Epoch 42/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1789 - acc: 0.9267\n",
      "Epoch 43/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1788 - acc: 0.9274\n",
      "Epoch 44/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1779 - acc: 0.9273\n",
      "Epoch 45/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1778 - acc: 0.9268\n",
      "Epoch 46/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1771 - acc: 0.9274\n",
      "Epoch 47/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1769 - acc: 0.9273\n",
      "Epoch 48/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1769 - acc: 0.9274\n",
      "Epoch 49/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1764 - acc: 0.9276\n",
      "Epoch 50/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1761 - acc: 0.9284\n",
      "Epoch 51/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1761 - acc: 0.9284\n",
      "Epoch 52/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1757 - acc: 0.9289\n",
      "Epoch 53/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1759 - acc: 0.9279\n",
      "Epoch 54/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1750 - acc: 0.9290\n",
      "Epoch 55/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1745 - acc: 0.9292\n",
      "Epoch 56/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1743 - acc: 0.9288 1s - \n",
      "Epoch 57/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1743 - acc: 0.9289\n",
      "Epoch 58/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1733 - acc: 0.9296\n",
      "Epoch 59/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1738 - acc: 0.9295\n",
      "Epoch 60/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1733 - acc: 0.9293\n",
      "Epoch 61/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1729 - acc: 0.9288\n",
      "Epoch 62/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1730 - acc: 0.9294\n",
      "Epoch 63/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1727 - acc: 0.9297\n",
      "Epoch 64/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1720 - acc: 0.9302 2s -  - ETA: 0s - loss: 0.1\n",
      "Epoch 65/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1721 - acc: 0.9299\n",
      "Epoch 66/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1714 - acc: 0.9309 0s - loss:\n",
      "Epoch 67/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1716 - acc: 0.9301\n",
      "Epoch 68/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1719 - acc: 0.9296\n",
      "Epoch 69/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1710 - acc: 0.9304 2s - loss: 0.1703 - acc: 0\n",
      "Epoch 70/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1702 - acc: 0.9309 2s - loss: 0.1712 - acc: 0.\n",
      "Epoch 71/100\n",
      "104051/104051 [==============================] - 11s 106us/step - loss: 0.1703 - acc: 0.9305\n",
      "Epoch 72/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1703 - acc: 0.9310\n",
      "Epoch 73/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1698 - acc: 0.9308\n",
      "Epoch 74/100\n",
      "104051/104051 [==============================] - 10s 100us/step - loss: 0.1697 - acc: 0.9310\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1694 - acc: 0.9311\n",
      "Epoch 76/100\n",
      "104051/104051 [==============================] - 10s 99us/step - loss: 0.1699 - acc: 0.9307 1s - loss: 0.1706 - acc: 0.9 - ETA: 1s - loss\n",
      "Epoch 77/100\n",
      "104051/104051 [==============================] - 11s 104us/step - loss: 0.1689 - acc: 0.9310\n",
      "Epoch 78/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1694 - acc: 0.9309\n",
      "Epoch 79/100\n",
      "104051/104051 [==============================] - 10s 98us/step - loss: 0.1687 - acc: 0.9310\n",
      "Epoch 80/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1693 - acc: 0.9309\n",
      "Epoch 81/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1688 - acc: 0.9315\n",
      "Epoch 82/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1685 - acc: 0.9312\n",
      "Epoch 83/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1677 - acc: 0.9322\n",
      "Epoch 84/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1675 - acc: 0.9321\n",
      "Epoch 85/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1676 - acc: 0.9317\n",
      "Epoch 86/100\n",
      "104051/104051 [==============================] - 10s 99us/step - loss: 0.1678 - acc: 0.9316\n",
      "Epoch 87/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1676 - acc: 0.9320 1\n",
      "Epoch 88/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1679 - acc: 0.9319\n",
      "Epoch 89/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1676 - acc: 0.9313\n",
      "Epoch 90/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1668 - acc: 0.9320\n",
      "Epoch 91/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1673 - acc: 0.9323 1s - loss:\n",
      "Epoch 92/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1665 - acc: 0.9325\n",
      "Epoch 93/100\n",
      "104051/104051 [==============================] - 10s 99us/step - loss: 0.1667 - acc: 0.9317\n",
      "Epoch 94/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1667 - acc: 0.9324\n",
      "Epoch 95/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1661 - acc: 0.9326\n",
      "Epoch 96/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1659 - acc: 0.9328\n",
      "Epoch 97/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1662 - acc: 0.9327\n",
      "Epoch 98/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1654 - acc: 0.9330\n",
      "Epoch 99/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1658 - acc: 0.9320\n",
      "Epoch 100/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1655 - acc: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d82e358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104051/104051 [==============================] - 1s 11us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16577561138220748, 0.9322255432472272]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18658     0]\n",
      " [ 7355     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717256756237266"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1573 - acc: 0.9369\n",
      "Epoch 2/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1573 - acc: 0.9365\n",
      "Epoch 3/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1574 - acc: 0.9368\n",
      "Epoch 4/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1574 - acc: 0.9361\n",
      "Epoch 5/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1576 - acc: 0.9361\n",
      "Epoch 6/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1579 - acc: 0.9362\n",
      "Epoch 7/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1575 - acc: 0.9360\n",
      "Epoch 8/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1576 - acc: 0.9363\n",
      "Epoch 9/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1570 - acc: 0.9371\n",
      "Epoch 10/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1575 - acc: 0.9363\n",
      "Epoch 11/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1573 - acc: 0.9367\n",
      "Epoch 12/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1571 - acc: 0.9364\n",
      "Epoch 13/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1571 - acc: 0.9371\n",
      "Epoch 14/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1570 - acc: 0.9365\n",
      "Epoch 15/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1566 - acc: 0.9364\n",
      "Epoch 16/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1566 - acc: 0.9369\n",
      "Epoch 17/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1567 - acc: 0.9368\n",
      "Epoch 18/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1568 - acc: 0.9366\n",
      "Epoch 19/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1569 - acc: 0.9371\n",
      "Epoch 20/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1566 - acc: 0.9365\n",
      "Epoch 21/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1564 - acc: 0.9370\n",
      "Epoch 22/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1564 - acc: 0.9371\n",
      "Epoch 23/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1562 - acc: 0.9371\n",
      "Epoch 24/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1563 - acc: 0.9373\n",
      "Epoch 25/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1562 - acc: 0.9377\n",
      "Epoch 26/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1565 - acc: 0.9368\n",
      "Epoch 27/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1559 - acc: 0.9368\n",
      "Epoch 28/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1560 - acc: 0.9369: 0s - loss: 0.1538\n",
      "Epoch 29/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1559 - acc: 0.9375\n",
      "Epoch 30/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1559 - acc: 0.9371\n",
      "Epoch 31/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1562 - acc: 0.9369\n",
      "Epoch 32/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1559 - acc: 0.9375\n",
      "Epoch 33/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1560 - acc: 0.9375\n",
      "Epoch 34/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1553 - acc: 0.9378\n",
      "Epoch 35/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1560 - acc: 0.9367\n",
      "Epoch 36/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1554 - acc: 0.9375\n",
      "Epoch 37/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1556 - acc: 0.9376\n",
      "Epoch 38/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1561 - acc: 0.9371\n",
      "Epoch 39/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1552 - acc: 0.9373\n",
      "Epoch 40/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1553 - acc: 0.9372\n",
      "Epoch 41/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1551 - acc: 0.9376\n",
      "Epoch 42/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1552 - acc: 0.9374: 0s - loss: 0.1540 - acc:\n",
      "Epoch 43/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1553 - acc: 0.9375\n",
      "Epoch 44/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1551 - acc: 0.9373\n",
      "Epoch 45/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1555 - acc: 0.9372\n",
      "Epoch 46/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1549 - acc: 0.9376\n",
      "Epoch 47/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1552 - acc: 0.9381: 0s - loss: 0.1514 - ac\n",
      "Epoch 48/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1552 - acc: 0.9381\n",
      "Epoch 49/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1551 - acc: 0.9375\n",
      "Epoch 50/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1552 - acc: 0.9371\n",
      "Epoch 51/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1551 - acc: 0.9373\n",
      "Epoch 52/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1544 - acc: 0.9379\n",
      "Epoch 53/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1552 - acc: 0.9378\n",
      "Epoch 54/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1549 - acc: 0.9374\n",
      "Epoch 55/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1554 - acc: 0.9377\n",
      "Epoch 56/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1545 - acc: 0.9379\n",
      "Epoch 57/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1547 - acc: 0.9378\n",
      "Epoch 58/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1545 - acc: 0.9377: 0s - loss: 0.154\n",
      "Epoch 59/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1546 - acc: 0.9381: 0s - loss: 0.15\n",
      "Epoch 60/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1546 - acc: 0.9375\n",
      "Epoch 61/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1541 - acc: 0.9380\n",
      "Epoch 62/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1545 - acc: 0.9378\n",
      "Epoch 63/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1542 - acc: 0.9376\n",
      "Epoch 64/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1543 - acc: 0.9378\n",
      "Epoch 65/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1544 - acc: 0.9380\n",
      "Epoch 66/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1545 - acc: 0.9374: 0s - loss: 0.1568\n",
      "Epoch 67/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1547 - acc: 0.9376\n",
      "Epoch 68/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1540 - acc: 0.9380\n",
      "Epoch 69/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1541 - acc: 0.9381: 0s - loss: 0.1541 - acc: 0\n",
      "Epoch 70/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1545 - acc: 0.9371\n",
      "Epoch 71/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1536 - acc: 0.9382\n",
      "Epoch 72/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1541 - acc: 0.9380\n",
      "Epoch 73/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1537 - acc: 0.9380\n",
      "Epoch 74/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1543 - acc: 0.9375\n",
      "Epoch 75/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1541 - acc: 0.9379\n",
      "Epoch 76/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1540 - acc: 0.9383\n",
      "Epoch 77/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1539 - acc: 0.9380\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1540 - acc: 0.9380\n",
      "Epoch 79/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1537 - acc: 0.9376\n",
      "Epoch 80/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1533 - acc: 0.9383\n",
      "Epoch 81/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1536 - acc: 0.9380\n",
      "Epoch 82/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1538 - acc: 0.9378\n",
      "Epoch 83/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1535 - acc: 0.9381\n",
      "Epoch 84/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1534 - acc: 0.9383\n",
      "Epoch 85/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1538 - acc: 0.9383\n",
      "Epoch 86/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1537 - acc: 0.9386\n",
      "Epoch 87/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1534 - acc: 0.9380\n",
      "Epoch 88/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1533 - acc: 0.9382\n",
      "Epoch 89/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1542 - acc: 0.9381\n",
      "Epoch 90/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1536 - acc: 0.9383\n",
      "Epoch 91/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1534 - acc: 0.9380\n",
      "Epoch 92/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1531 - acc: 0.9381: 0s - loss: 0.1\n",
      "Epoch 93/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1536 - acc: 0.9385\n",
      "Epoch 94/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1530 - acc: 0.9385\n",
      "Epoch 95/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1533 - acc: 0.9382: 0s - loss: 0.1532 - acc: 0\n",
      "Epoch 96/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1530 - acc: 0.9387\n",
      "Epoch 97/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1530 - acc: 0.9384\n",
      "Epoch 98/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1530 - acc: 0.9381\n",
      "Epoch 99/100\n",
      "104051/104051 [==============================] - 1s 10us/step - loss: 0.1531 - acc: 0.9384\n",
      "Epoch 100/100\n",
      "104051/104051 [==============================] - 1s 11us/step - loss: 0.1531 - acc: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d82e160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
