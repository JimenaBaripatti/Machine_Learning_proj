{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "#always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "from src.data import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jbaripatti/machine_learning_proj/data/interim/\"\n",
    "name = 'data_interim.txt'\n",
    "filepath = path + name\n",
    "data = np.loadtxt(filepath, delimiter=\",\")\n",
    "X_train, y_train, X_test, y_test = make_dataset.split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = make_dataset.scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 50 input features and one target variable. \n",
    "### 2 Hidden layers. Each hidden layer will have 25 nodes.\n",
    "\n",
    "ReLu will be the activation function for hidden layers. As this is a binary classification problem we will use sigmoid as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(25, activation='relu', kernel_initializer='random_normal', input_dim=50))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(25, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104051/104051 [==============================] - 11s 103us/step - loss: 0.2337 - acc: 0.9084\n",
      "Epoch 2/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1823 - acc: 0.9254\n",
      "Epoch 3/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1731 - acc: 0.9298\n",
      "Epoch 4/100\n",
      "104051/104051 [==============================] - 11s 103us/step - loss: 0.1687 - acc: 0.9311\n",
      "Epoch 5/100\n",
      "104051/104051 [==============================] - 10s 98us/step - loss: 0.1655 - acc: 0.9327 0s - loss: 0.1654 - ac\n",
      "Epoch 6/100\n",
      "104051/104051 [==============================] - 10s 99us/step - loss: 0.1626 - acc: 0.9341 0s - loss: 0.1624 -\n",
      "Epoch 7/100\n",
      "104051/104051 [==============================] - 11s 101us/step - loss: 0.1774 - acc: 0.9352\n",
      "Epoch 8/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.2133 - acc: 0.9331\n",
      "Epoch 9/100\n",
      "104051/104051 [==============================] - 11s 101us/step - loss: 0.2118 - acc: 0.9338\n",
      "Epoch 10/100\n",
      "104051/104051 [==============================] - 10s 98us/step - loss: 0.2107 - acc: 0.9340\n",
      "Epoch 11/100\n",
      "104051/104051 [==============================] - 10s 100us/step - loss: 0.2093 - acc: 0.9344\n",
      "Epoch 12/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.2081 - acc: 0.9351\n",
      "Epoch 13/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.2006 - acc: 0.9362\n",
      "Epoch 14/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1517 - acc: 0.9400\n",
      "Epoch 15/100\n",
      "104051/104051 [==============================] - 10s 95us/step - loss: 0.1513 - acc: 0.9398\n",
      "Epoch 16/100\n",
      "104051/104051 [==============================] - 11s 102us/step - loss: 0.1503 - acc: 0.9408\n",
      "Epoch 17/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1499 - acc: 0.9409\n",
      "Epoch 18/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1492 - acc: 0.9407\n",
      "Epoch 19/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1486 - acc: 0.9406\n",
      "Epoch 20/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1765 - acc: 0.9394\n",
      "Epoch 21/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.2023 - acc: 0.9381: 0s - loss: 0.2021 - acc: 0.9\n",
      "Epoch 22/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.2019 - acc: 0.9383\n",
      "Epoch 23/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.2015 - acc: 0.9386\n",
      "Epoch 24/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1480 - acc: 0.9419\n",
      "Epoch 25/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1456 - acc: 0.9417\n",
      "Epoch 26/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1453 - acc: 0.9424\n",
      "Epoch 27/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1450 - acc: 0.9426\n",
      "Epoch 28/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1446 - acc: 0.9425\n",
      "Epoch 29/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1443 - acc: 0.9428: 1s \n",
      "Epoch 30/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1442 - acc: 0.9427\n",
      "Epoch 31/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1436 - acc: 0.9431: 0s - loss: 0.1431 - acc\n",
      "Epoch 32/100\n",
      "104051/104051 [==============================] - 10s 91us/step - loss: 0.1774 - acc: 0.9413 1s - loss\n",
      "Epoch 33/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1980 - acc: 0.9399\n",
      "Epoch 34/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1972 - acc: 0.9404: 1s - lo\n",
      "Epoch 35/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1972 - acc: 0.9401\n",
      "Epoch 36/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1714 - acc: 0.9417\n",
      "Epoch 37/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1418 - acc: 0.9440\n",
      "Epoch 38/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1415 - acc: 0.9439\n",
      "Epoch 39/100\n",
      "104051/104051 [==============================] - 10s 92us/step - loss: 0.1409 - acc: 0.9445\n",
      "Epoch 40/100\n",
      "104051/104051 [==============================] - 10s 92us/step - loss: 0.1412 - acc: 0.9443\n",
      "Epoch 41/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1408 - acc: 0.9442\n",
      "Epoch 42/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1405 - acc: 0.9445\n",
      "Epoch 43/100\n",
      "104051/104051 [==============================] - 10s 101us/step - loss: 0.1400 - acc: 0.9448\n",
      "Epoch 44/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1398 - acc: 0.9449\n",
      "Epoch 45/100\n",
      "104051/104051 [==============================] - 10s 98us/step - loss: 0.1396 - acc: 0.9443\n",
      "Epoch 46/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1394 - acc: 0.9449\n",
      "Epoch 47/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1394 - acc: 0.9447\n",
      "Epoch 48/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1392 - acc: 0.9442\n",
      "Epoch 49/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1392 - acc: 0.9451\n",
      "Epoch 50/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1388 - acc: 0.9449\n",
      "Epoch 51/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1382 - acc: 0.9454\n",
      "Epoch 52/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1386 - acc: 0.9451\n",
      "Epoch 53/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1381 - acc: 0.9460: 0s - loss: 0.1379 \n",
      "Epoch 54/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1383 - acc: 0.9454\n",
      "Epoch 55/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1377 - acc: 0.9464\n",
      "Epoch 56/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1380 - acc: 0.9456\n",
      "Epoch 57/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1376 - acc: 0.9462\n",
      "Epoch 58/100\n",
      "104051/104051 [==============================] - 10s 91us/step - loss: 0.1375 - acc: 0.9458\n",
      "Epoch 59/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1374 - acc: 0.9457\n",
      "Epoch 60/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1367 - acc: 0.9458\n",
      "Epoch 61/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1368 - acc: 0.9460\n",
      "Epoch 62/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1366 - acc: 0.9461\n",
      "Epoch 63/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1370 - acc: 0.9459\n",
      "Epoch 64/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1360 - acc: 0.9464\n",
      "Epoch 65/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1361 - acc: 0.9465\n",
      "Epoch 66/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1362 - acc: 0.9462:\n",
      "Epoch 67/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1358 - acc: 0.9468\n",
      "Epoch 68/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1359 - acc: 0.9460\n",
      "Epoch 69/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1357 - acc: 0.9466\n",
      "Epoch 70/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1355 - acc: 0.9467\n",
      "Epoch 71/100\n",
      "104051/104051 [==============================] - 9s 88us/step - loss: 0.1352 - acc: 0.9464\n",
      "Epoch 72/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1354 - acc: 0.9464\n",
      "Epoch 73/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1348 - acc: 0.9473\n",
      "Epoch 74/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1350 - acc: 0.9472\n",
      "Epoch 75/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1351 - acc: 0.9464\n",
      "Epoch 76/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1347 - acc: 0.9470\n",
      "Epoch 77/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1344 - acc: 0.9471\n",
      "Epoch 78/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1343 - acc: 0.9474\n",
      "Epoch 79/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1340 - acc: 0.9472\n",
      "Epoch 80/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1343 - acc: 0.9470\n",
      "Epoch 81/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1342 - acc: 0.9470\n",
      "Epoch 82/100\n",
      "104051/104051 [==============================] - 10s 94us/step - loss: 0.1338 - acc: 0.9471\n",
      "Epoch 83/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1339 - acc: 0.9477\n",
      "Epoch 84/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1334 - acc: 0.9475: \n",
      "Epoch 85/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1330 - acc: 0.9480\n",
      "Epoch 86/100\n",
      "104051/104051 [==============================] - 9s 89us/step - loss: 0.1333 - acc: 0.9476\n",
      "Epoch 87/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1333 - acc: 0.9472: 0s - loss: 0.1334 - acc: 0.947\n",
      "Epoch 88/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1334 - acc: 0.9481\n",
      "Epoch 89/100\n",
      "104051/104051 [==============================] - 10s 101us/step - loss: 0.1332 - acc: 0.9474\n",
      "Epoch 90/100\n",
      "104051/104051 [==============================] - 10s 98us/step - loss: 0.1329 - acc: 0.9476\n",
      "Epoch 91/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1327 - acc: 0.9472\n",
      "Epoch 92/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1329 - acc: 0.9482\n",
      "Epoch 93/100\n",
      "104051/104051 [==============================] - 9s 90us/step - loss: 0.1330 - acc: 0.9482\n",
      "Epoch 94/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1322 - acc: 0.9481\n",
      "Epoch 95/100\n",
      "104051/104051 [==============================] - 10s 97us/step - loss: 0.1326 - acc: 0.9477\n",
      "Epoch 96/100\n",
      "104051/104051 [==============================] - 11s 105us/step - loss: 0.1319 - acc: 0.9480A: 0s - loss: 0.1321 \n",
      "Epoch 97/100\n",
      "104051/104051 [==============================] - 10s 96us/step - loss: 0.1322 - acc: 0.9477\n",
      "Epoch 98/100\n",
      "104051/104051 [==============================] - 9s 91us/step - loss: 0.1323 - acc: 0.9475\n",
      "Epoch 99/100\n",
      "104051/104051 [==============================] - 10s 93us/step - loss: 0.1321 - acc: 0.9481\n",
      "Epoch 100/100\n",
      "104051/104051 [==============================] - 10s 92us/step - loss: 0.1320 - acc: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d82e2e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104051/104051 [==============================] - 1s 11us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12995500298622456, 0.948717455860126]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18658     0]\n",
      " [ 7355     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717256756237266"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitting the training set. I will tune a ANN with 1 hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import train_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Batch Size and Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a447c6f28>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize model\n",
    "train_model.create_model_batch_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=train_model.create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 100, 1000]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/finalprojectML/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/envs/finalprojectML/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.936973 using {'batch_size': 10, 'epochs': 100}\n",
      "0.929832 (0.001010) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.935282 (0.001335) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.936973 (0.001509) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.924720 (0.001334) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.932427 (0.000978) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.936839 (0.001878) with: {'batch_size': 100, 'epochs': 100}\n",
      "0.896061 (0.002757) with: {'batch_size': 1000, 'epochs': 10}\n",
      "0.927920 (0.000533) with: {'batch_size': 1000, 'epochs': 50}\n",
      "0.931553 (0.001205) with: {'batch_size': 1000, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "train_model.get_best_result(param_grid, model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/finalprojectML/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a24d260b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initizalize model\n",
    "train_model.create_model_lrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=train_model.create_model_lrate, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.1, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/finalprojectML/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Best: 0.917223 using {'learn_rate': 0.1}\n",
      "0.917223 (0.003255) with: {'learn_rate': 0.1}\n",
      "0.905335 (0.010542) with: {'learn_rate': 0.9}\n"
     ]
    }
   ],
   "source": [
    "train_model.get_best_result(param_grid, model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of a tuned ANN classifier\n",
    "\n",
    "'batch_size': 10, 'epochs': 50}\n",
    "'learn_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.2720 - acc: 0.8857: 3s - loss: 0.2838 - ac - ETA: 2s - loss: - ETA\n",
      "Epoch 2/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2481 - acc: 0.8954\n",
      "Epoch 3/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2400 - acc: 0.8992: 4s - - ET - ETA: 1s\n",
      "Epoch 4/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2343 - acc: 0.9021: 3s - loss - ETA: 2s - l - ETA: 0s - loss: 0.2\n",
      "Epoch 5/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2292 - acc: 0.9041ETA: 3s - loss: 0.2304 - acc: - - ETA: 1s - \n",
      "Epoch 6/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2258 - acc: 0.9056: 4s - - ETA: 3s -  - ETA: 0s - loss: 0.2258 - acc: 0.90\n",
      "Epoch 7/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2231 - acc: 0.9069\n",
      "Epoch 8/50\n",
      "104051/104051 [==============================] - 7s 72us/step - loss: 0.2207 - acc: 0.9080: 6s - loss: 0.2225 -  - E - ETA: 4s - loss: 0.2196 - acc:  - ETA: 4s - loss: 0.2199 - acc:\n",
      "Epoch 9/50\n",
      "104051/104051 [==============================] - 7s 71us/step - loss: 0.2187 - acc: 0.9080: 5s - loss: 0.2144 - acc - ETA: 0s - loss: \n",
      "Epoch 10/50\n",
      "104051/104051 [==============================] - 7s 72us/step - loss: 0.2163 - acc: 0.9108\n",
      "Epoch 11/50\n",
      "104051/104051 [==============================] - 7s 72us/step - loss: 0.2148 - acc: 0.9109: 7s - loss: 0.2131 -  - ETA: 6s - loss: 0.2127 - a - ETA: 6s - loss:  - ETA: 5s - loss - ETA: 3s - loss: 0.2138 - acc: 0.911 - ETA: 3s -  - ETA:  - ETA: 0s - loss: 0.2 - ETA: 0s - loss: 0.2146 - acc: 0.\n",
      "Epoch 12/50\n",
      "104051/104051 [==============================] - 7s 72us/step - loss: 0.2131 - acc: 0.9119: 5s - lo - ETA: 2s - loss: 0.2 - ETA: 2s - loss: 0.2146 - acc: 0.9 - ETA: 1s - loss: 0.2145 -  - ETA: 1s -\n",
      "Epoch 13/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2115 - acc: 0.9127: 1s - lo\n",
      "Epoch 14/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2095 - acc: 0.9134: 7s - loss: 0.220 - ETA: 6s - loss: 0. - ETA: 5s - loss: 0.2155  - ETA: 4s - loss: 0.2161 - acc: 0. - ETA: - ETA: 1s - loss: 0.2105 - - ETA: 0s - loss: 0.2100 - a\n",
      "Epoch 15/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2093 - acc: 0.9137: 7s - loss: 0.201 - ETA: 4s - loss: 0.20 - ETA: - ETA: 1s - loss: 0.2090 - ac - ETA: 1\n",
      "Epoch 16/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2074 - acc: 0.9149: 7s - loss:  - ETA: 2s - loss: 0.2071  - ETA: 1s - loss: 0.207 - ETA: 0s - loss: 0.2\n",
      "Epoch 17/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2064 - acc: 0.9149 - ET - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.2071 - acc: 0.9 - ETA: 1s - loss: 0.2069 - acc: 0.914 - ETA: 1s - loss: 0.2068 - acc: 0 - ETA: 1s - loss: 0.2062 - acc: 0.914 - ETA: 1s - loss: 0.2064 - acc: 0. - ETA: 1s - loss: 0.20 - ETA: 0s - loss: 0.2063 - acc: 0\n",
      "Epoch 18/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.2054 - acc: 0.9153: 7s - loss: 0.1963 - acc:  - ETA: 7s - loss: 0. - ETA: 6s - loss: 0.1989 - acc: 0 - ETA: 5s - loss: 0.2007 - acc - ETA: 3s - loss: 0.2028 - acc: 0.91 - ETA: 3s - loss: 0.2036 - - ETA: 2s - loss: 0.2034 - a - ETA: 2s - - ETA: 0s - loss: 0.2047 - ETA: 0s - loss: 0.2053 - acc: 0\n",
      "Epoch 19/50\n",
      "104051/104051 [==============================] - 8s 76us/step - loss: 0.2043 - acc: 0.9163: 7s - l - ETA: 4s - loss: 0.2039 - acc: 0.916 - ETA: 4s  - ETA: 2s - loss: 0. - ETA: 1s - loss: 0.2031 - acc: 0.9 - ETA: 1s - loss: 0.2030 - acc: - ETA: 1s - los\n",
      "Epoch 20/50\n",
      "104051/104051 [==============================] - 7s 72us/step - loss: 0.2041 - acc: 0.9156: 3s - loss: 0.2070 - acc: - ETA: 3s - loss: 0. - ETA: 0s - loss: 0.2049 - acc: 0.9 - ETA: 0s - loss: 0.2049 -\n",
      "Epoch 21/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2035 - acc: 0.9165: 3s - ETA: 2s - los - ETA: 1s - lo\n",
      "Epoch 22/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2022 - acc: 0.9172: 6s - loss: 0.2034 - acc: 0 - ETA: 5 - ETA: 4s - loss: 0.2011 - acc: 0. - ETA: 4s - loss: 0.20 - ETA: 3s  - ETA: 2s - loss: - ETA: 0s - loss: \n",
      "Epoch 23/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2014 - acc: 0.9173: 2s - loss: 0.2015 - acc:  - ETA: 2s - loss: 0.2015 - acc: 0.91 - ETA: 1s - loss: 0.2016 - a - ETA: 1s -  - ETA: 0s - loss: 0.2009 - acc: 0.917 - ETA: 0s - loss: 0.2010 - acc: 0.9\n",
      "Epoch 24/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.2000 - acc: 0.9182 - ETA: 4s - loss: 0.199 - ETA: 4s - loss: 0.2003 - acc: 0. - ETA: 3s - loss: 0.2 - ETA: 3s - loss: 0.2003 -  - ETA: 2s - loss: 0.2008 - acc: 0.918 - ETA: 2s - - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.2000 - acc: 0.\n",
      "Epoch 25/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.2000 - acc: 0.9178: 5s - loss: 0.20 - ETA: 4s - loss: 0.1977 - acc: 0.918 - ETA:  - ETA: 3s - loss: 0.200 - ETA: 2s - loss: 0.1998 - acc: 0.9 - ETA: 2s  - ETA: 0s - loss: 0.1993 - acc: 0.9 - ETA: 0s - loss: 0.1996\n",
      "Epoch 26/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.1994 - acc: 0.9191: 6s - loss: 0.1936 - acc:  - ETA: 4s -  - ETA: 3s  - ETA: 1s - loss: 0.1986 - ETA: 1s - loss: 0.1990  - ETA: 0s - loss: 0.1991 - acc\n",
      "Epoch 27/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.1982 - acc: 0.9190: 6s - loss: 0.1958 - ETA: 5s - loss: 0.1953 - acc: 0 - ETA: 5s - loss: 0.1956 - ETA: 4s  - ETA: 2s - loss: 0.1990 - acc: 0.918 - ETA: 2s - loss: 0.1990 -  - ETA: 2s - - ETA: 0s - loss: 0.1993 - acc - ETA: 0s - loss: 0.1986 -\n",
      "Epoch 28/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.1980 - acc: 0.9188: 6s - loss: 0.1952 - acc: 0.919 - ETA: 6s - loss: 0.1952 - - ETA: 6s - loss: 0.1944 - - ETA: 5s - loss: 0 - ETA: 4s - loss: 0.1989 - acc:  - ETA: 4s - loss: 0.1975 - - ETA: 3s - loss: 0.1969 - acc - ETA: 3s - loss: 0 - ETA: 2s - lo - ETA: 1s - loss: 0.1990 -  - ETA: 0s - loss: 0.1985 - ac\n",
      "Epoch 29/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.1978 - acc: 0.9192: 3s - loss: 0.1981 - acc: 0.918 - ETA: 3s - loss: 0.1980 - ETA: 3s - loss: 0.1977 - acc: 0.9 - ETA: 2s - loss: 0.1983 - acc: 0. - ETA: 2s - loss: 0.1988 - acc: 0.91 - ETA: 2s - loss: 0.1 - ETA: 1s - loss: 0.1 - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.1978 - acc: 0.919\n",
      "Epoch 30/50\n",
      "104051/104051 [==============================] - 8s 77us/step - loss: 0.1960 - acc: 0.9199: 4s - loss: 0.1929  - ETA: 3s  - - ETA: 0s - loss: 0.\n",
      "Epoch 31/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.1963 - acc: 0.9196 - ETA:  - ETA: 2s - loss: 0.1952 - acc: 0.91 - ETA: 2s  - ETA: 0s - loss: 0.1962 \n",
      "Epoch 32/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.1955 - acc: 0.9204: 7s - loss: 0 - ETA: 4s - loss: 0.1940 - acc: 0.921 - ETA: 4s - loss: 0.1943 - acc - ETA: 3s - loss: 0.1954 -  - ETA: 1s - lo\n",
      "Epoch 33/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.1951 - acc: 0.9208: 6s - loss: 0.2019 - acc: 0. - ETA: 6s - loss: 0.1980 - acc: 0.91 - ETA: 6s - loss: 0.1997 - acc: 0.9 - ETA: 6s - loss: 0.1971 - ETA: 5s - loss: 0.1973 - acc: 0.92 - ETA: 5s - loss: 0.1968 - acc: 0.92 - ETA: 5s - loss: 0.19 - ETA: 4s -  - ETA: 3s - loss: 0.19 - ETA: 2s - loss: 0.19 \n",
      "Epoch 34/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.1941 - acc: 0.9206: 4s - loss: 0.1965 - acc: - ETA: 4s - loss: 0.1955 - ac - ETA: 3s - - ETA: 2s - loss: 0.1948 - a - ETA: 2s - ETA: 0s - loss: 0.194\n",
      "Epoch 35/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.1945 - acc: 0.9209: 4s - loss: 0.1917 - acc: 0.92 - ETA: 4s - - ETA: 2s - - ETA: 1\n",
      "Epoch 36/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2565 - acc: 0.9140: 2s - los - ETA: 0s - loss: 0.2560 - acc: 0.913 - ETA: 0s - loss: 0.2561 - acc: 0.9 - ETA: 0s - loss: 0.2551 - acc: 0 - ETA: 0s - loss: 0.2562 - acc: 0.9 - ETA: 0s - loss: 0.2555 - acc: \n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2490 - acc: 0.9180: 5s - loss: 0.2614 - acc: 0.917 - ETA: 5s - loss: 0.2612 - - ETA: 5s - loss: 0.2570 - acc: 0.917 - ETA: 1s - loss: 0.2493 - acc: 0.917 - ETA: 1s - loss:  - ETA: 0s - loss: 0.2493 - acc: 0\n",
      "Epoch 38/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2481 - acc: 0.9183: 6s - loss: 0.2404 - acc: 0.914 - ETA: 6s - loss: 0.2379 - acc: 0. - ETA: 6s -  - ETA: 5s - loss: 0.2540 - - ETA: 4s - - ETA: 3s - loss: 0.2496 - acc: 0.91 - ETA: 3s - los - ETA: 1s - loss: 0.2489 - acc: 0. - ETA: 1s - loss - ETA: 0s - loss: 0.2480 -\n",
      "Epoch 39/50\n",
      "104051/104051 [==============================] - 8s 72us/step - loss: 0.2467 - acc: 0.9185: 7s  - - ETA: 3s - loss: 0.2459 - acc: 0.91 - ETA: 3s - loss: 0.2456 - a - ETA: 3s - loss: 0.2489 - a - ETA: 2s - loss: 0.2478 - - ETA: 2s  - ETA: 0s - loss: 0.2\n",
      "Epoch 40/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.2467 - acc: 0.9186: 6s - loss: 0.2456 - acc: 0. - ETA: 5s - loss: 0.2435 -  - ETA: 5s - loss: 0.2415 - acc: - ETA: 4s - los - ETA: 3s - loss: 0.24 - ETA: 3s - loss: 0.2457 -  - ETA: 2s - loss: 0.2446 - acc: 0.9 - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.244 - ETA: 0s - loss: 0.24\n",
      "Epoch 41/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2463 - acc: 0.9193: 6s - loss: 0.2468 - acc: 0. - ETA: 6s - loss: 0.2459 - acc: 0.920 - ETA: 6s - loss: 0.2 - ETA: 5s -  - ETA: 4s - loss: 0.2498 - acc: - ETA: 1s - loss: 0.2491 - acc:  - ETA: 1s - loss - ETA: 0s - loss: 0.2475 - acc: 0.919 - ETA: 0s - loss: 0.2471 - acc: 0 - ETA: 0s - loss: 0.2467 - acc: 0.91 - ETA: 0s - loss: 0.2464 - acc: 0.919\n",
      "Epoch 42/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2462 - acc: 0.9192: 6s - loss: 0.2515 - ETA: 5s - los - ETA: 4s - loss: 0.2449 - acc: 0.919 - ET - ETA: 2s - loss: 0.2441 - acc:  - ETA: 2s - loss: 0.2453 - acc: 0.91 - ETA: 2s - loss: 0.2460 - ETA: 1s - loss: 0.2464 - acc: 0.919 - ETA: 1s - loss: 0.2472 - acc: 0.91 - ETA: 1s - loss: - ETA: 0s - loss: 0.2462 - acc: - ETA: 0s - loss: 0.2462 - acc: \n",
      "Epoch 43/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2463 - acc: 0.9187: 6s - loss: 0.2488 - - ETA: 5s - loss: 0.2596 - acc: 0 - ETA: 5s - loss: 0.25 - E - ETA: 0s - loss: 0.2483 - acc: 0 - ETA: 0s - loss: 0.2477 - a\n",
      "Epoch 44/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2455 - acc: 0.9191: 1s - loss:\n",
      "Epoch 45/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.2450 - acc: 0.9189: 6s - loss: 0.2476 - acc: 0. - ETA: 6s - loss:  - ETA: - ETA: 4s - loss: 0.2453 - ETA: 3s  - ETA: 0s - loss: 0.2452 - acc: 0.\n",
      "Epoch 46/50\n",
      "104051/104051 [==============================] - 8s 74us/step - loss: 0.2445 - acc: 0.9197: 4s - loss: 0.2 - ETA: 1s - loss: 0.2426 - acc: - ETA: 1s - loss: 0.2431 - ETA: 0s - loss: 0.2437 - acc: 0.91 - ETA: 0s - loss: 0.2447 - acc: 0\n",
      "Epoch 47/50\n",
      "104051/104051 [==============================] - 8s 73us/step - loss: 0.2448 - acc: 0.9199: 5s - loss: - ETA: 5s - loss: 0.2465 - acc: 0.919 - ETA: - ETA: 3s - loss: 0.2456  - - ETA: 0s - loss: 0\n",
      "Epoch 48/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.2439 - acc: 0.9198: 5s - loss:  - ETA: 3s - loss: 0.2439 - acc: 0.91 - ETA: 3s - loss: 0.2444  - ETA: 2s - loss: 0.2441 - acc:  - ETA: - ETA: 0s - loss: 0.2437 -\n",
      "Epoch 49/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.2444 - acc: 0.9201: 6s - loss: 0.2470  - ETA: 5s - loss: 0. - ETA: 4s - loss: 0.238 - ETA:  - ETA: 2s - loss: 0.2429 - ETA\n",
      "Epoch 50/50\n",
      "104051/104051 [==============================] - 8s 75us/step - loss: 0.2439 - acc: 0.9200: - ETA: 0s - loss: 0.2425 -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a34cedf98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "learn_rate = 0.1\n",
    "optimizer = SGD(lr=learn_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train, batch_size=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104051/104051 [==============================] - 1s 11us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23604808641220038, 0.9232780079039821]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=model.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9216929996540192"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The performance of the tuned Neural Network classifier is comparable to the performance of the RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
